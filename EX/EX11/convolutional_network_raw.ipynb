{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBKyt1b40TRA"
   },
   "source": [
    "#  Bài tâp về mạng tích chập\n",
    "\n",
    "Trong bài này, chúng ta sẽ xây dựng một mạng tích chập sử dụng Torch và thử train&Test tập MNIST nhé. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRMw1k_n0YY5"
   },
   "source": [
    "## Tổng quan một mạng CNN cơ bản\n",
    "\n",
    "![CNN](http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/images/fig3.png)\n",
    "\n",
    "## MNIST dataset\n",
    "\n",
    "Trong bài tập này, chúng ta sẽ sử dựng tập MNIST rất nổi tiếng vể  các chữ số viết tay từ 0->9. Tập dataset này bao gồm 60000 ảnh cho training và 10000 ảnh cho testing. Các bức ảnh này đều đã được căn giữa và chỉnh với kích thước cố định là 28x28.\n",
    "\n",
    "Trong phần tiền xử lý, chúng ta sẽ cần chuẩn hóa các giá trị pixel của mỗi ảnh về khoảng [0,1], kiểu dữ liệu sẽ là float32\n",
    "\n",
    "<!-- ![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png) -->\n",
    "\n",
    "Chi tiết tại: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_bmBxOZW0UGC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtTud_GsLWP_"
   },
   "source": [
    "# Some configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3z4BK0Vr0bGV"
   },
   "outputs": [],
   "source": [
    "# Số classes trong tập MNIST\n",
    "num_classes = 10\n",
    "\n",
    "# Số epoch \n",
    "epochs = 3\n",
    "\n",
    "# Các tham số cần thiết cho quá trình traning.\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Tham số mạng CNN \n",
    "out_channel_1  = 32 # số channel của đầu ra conv thứ 1\n",
    "out_channel_2 = 64 # số channel của đầu ra conv thứ 2\n",
    "\n",
    "# Path lưu best model \n",
    "checkpoint = 'model.pth' # có thể để dạng *.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2vYvX5WLaX2"
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "f_F7wyna9NR7"
   },
   "outputs": [],
   "source": [
    "# Transform image \n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) \n",
    "    ])\n",
    "\n",
    "# load dataset từ torchvision.datasets\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True,transform=transform)\n",
    "test_dataset = datasets.MNIST('../data', train=False,transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5UxaA9xLczc"
   },
   "source": [
    "# Model\n",
    "\n",
    "- Input shape sẽ là: [-1, 28, 28, 1]. Ở đây -1 sẽ thể hiện batchsize, một batch thì gồm nhiều ảnh 28x28x1 (grayscale, số channel là 1 !)\n",
    "- Chúng ta sẽ định nghĩa một model đơn giản gồm 2 lớp Conv đều có filter size là 3x3 và stride hãy set là 1. \n",
    "- Ngoài ra sẽ có một lớp maxpool, set filter size 2x2\n",
    "- Flow như sau: conv2d_1 -> relu -> conv2d_2 -> relu -> maxpool2d -> dropout -> flatten -> linear1 -> relu -> dropout -> linear2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2jfcloyb0dQ9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! Hãy train để có checkpoint file\n"
     ]
    }
   ],
   "source": [
    "# Định nghĩa model \n",
    "\n",
    "model = nn.Sequential (\n",
    "    nn.Conv2d(1, 32, 3, 1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 64, 3, 1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(9216, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(64, 10)       \n",
    ")\n",
    "\n",
    "# load lại pretrained model (nếu có)\n",
    "try:\n",
    "  model.load_state_dict(torch.load(checkpoint))\n",
    " \n",
    "except:\n",
    "  print(\"!!! Hãy train để có checkpoint file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "20fGKBm6BMRB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tTrain Loss: 0.087821\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tTrain Loss: 0.041964\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tTrain Loss: 0.069458\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tTrain Loss: 0.141109\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tTrain Loss: 0.135354\n",
      "***********    TEST_ACC = 98.45%    ***********\n",
      "Train Epoch: 2 [0/60000 (0%)]\tTrain Loss: 0.066775\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tTrain Loss: 0.068246\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tTrain Loss: 0.046371\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tTrain Loss: 0.075029\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tTrain Loss: 0.196693\n",
      "***********    TEST_ACC = 98.77%    ***********\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "best_val_loss = 999\n",
    "\n",
    "for epoch in range(1,epochs):\n",
    "    # Quá trình training \n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % display_step == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    # Quá trình testing \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    # set no grad cho quá trình testing\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            output = F.log_softmax(output,dim=1) # log softmax using F\n",
    "            test_loss += criterion(output, target)\n",
    "            pred = output.argmax(dim = 1,keepdim = True) # argmax để lấy predicted label, chú ý keepdim = True\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset) \n",
    "    if test_loss < best_val_loss:\n",
    "      best_val_loss = test_loss\n",
    "      torch.save(model.state_dict(), checkpoint)  # Lưu lại model\n",
    "      print(\"***********    TEST_ACC = {}%    ***********\".format(correct/100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NAtF8XBN_l6"
   },
   "source": [
    "# Visualize Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rzU5GUQqGBH5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (3): ReLU()\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Dropout(p=0.3, inplace=False)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=9216, out_features=64, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Dropout(p=0.4, inplace=False)\n",
       "  (10): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load lại model đã train\n",
    "model.load_state_dict(torch.load(checkpoint))\n",
    "# set eval phase \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RD8Z-ZX_Mlsp"
   },
   "outputs": [],
   "source": [
    "item = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3kC33zgmM5ZI"
   },
   "outputs": [],
   "source": [
    "data,target = next(item) # lấy một batch ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "t1-GZt14N-ym"
   },
   "outputs": [],
   "source": [
    "test_idx = random.choice(range(len(data))) # lấy index của một phần tử của một batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OkahsgWAOo6i"
   },
   "outputs": [],
   "source": [
    "data = data[test_idx]\n",
    "target = target[test_idx]\n",
    "assert data.shape == (1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DCHOlzBvMznD"
   },
   "outputs": [],
   "source": [
    "# thử predict \n",
    "\n",
    "def plot(data,model):\n",
    "  data = torch.unsqueeze(data,dim=0) # unsqueeze data\n",
    "  output = model(data)\n",
    "  output = F.log_softmax(output,dim=1) # log softmax, chú ý dim\n",
    "  pred = output.argmax(dim=1,keepdim=True) # argmax, chú ý keepdim \n",
    "  print(\"Predict Number : \", pred[0][0].numpy()) \n",
    "  plt.imshow(data[0][0],cmap='gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1629979771991,
     "user": {
      "displayName": "Max Ph",
      "photoUrl": "",
      "userId": "05319390549713197190"
     },
     "user_tz": -420
    },
    "id": "Ci0XeQngPdtB",
    "outputId": "1deafd0a-7a63-4527-da81-9dfa44be20ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Number :  9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGXhJREFUeJzt3XFolPcdx/HPafWauvMwxOQuM4awKVurSI0umrUaxaYGZmvjwLZsxD8mbY2CSzuZlWE6mBFB6R9pXSfF6VpXt2mdoNSmaKJbZrFBqbji4owzmzmCwd3FqAnqb3+Ix65JrU+8yzeXvF/wQHP3fL2fz5759vEuT3zOOScAAAyMsF4AAGD4IkIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMDMQ9YL+LLbt2/r0qVLCgQC8vl81ssBAHjknFNnZ6dyc3M1YsS9r3UGXYQuXbqkvLw862UAAB5Qa2urJkyYcM99Bt0/xwUCAeslAACS4H7+PE9ZhN5++20VFBTo4YcfVmFhoY4dO3Zfc/wTHAAMDffz53lKIrR7926tXr1a69at08mTJ/Xkk0+qrKxMFy9eTMXLAQDSlC8Vd9EuKirS9OnTtXXr1vhj3/3ud7V48WLV1NTcczYWiykYDCZ7SQCAARaNRjV27Nh77pP0K6Genh41NTWptLQ04fHS0lI1Njb22r+7u1uxWCxhAwAMD0mP0OXLl3Xr1i3l5OQkPJ6Tk6NIJNJr/5qaGgWDwfjGJ+MAYPhI2QcTvvyGlHOuzzep1q5dq2g0Gt9aW1tTtSQAwCCT9O8TysrK0siRI3td9bS3t/e6OpIkv98vv9+f7GUAANJA0q+ERo8ercLCQtXV1SU8XldXp+Li4mS/HAAgjaXkjglVVVX68Y9/rBkzZmj27Nn6zW9+o4sXL+rll19OxcsBANJUSiK0dOlSdXR06Je//KXa2to0ZcoUHTx4UPn5+al4OQBAmkrJ9wk9CL5PCACGBpPvEwIA4H4RIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZh6yXgAwHP30pz/1PFNeXu555r333vM8I0nvvPNOv+YAr7gSAgCYIUIAADNJj1B1dbV8Pl/CFgqFkv0yAIAhICXvCT322GP65JNP4l+PHDkyFS8DAEhzKYnQQw89xNUPAOBrpeQ9oebmZuXm5qqgoEDPP/+8zp8//5X7dnd3KxaLJWwAgOEh6REqKirSzp07dejQIW3btk2RSETFxcXq6Ojoc/+amhoFg8H4lpeXl+wlAQAGqaRHqKysTEuWLNHUqVO1YMECHThwQJK0Y8eOPvdfu3atotFofGttbU32kgAAg1TKv1l1zJgxmjp1qpqbm/t83u/3y+/3p3oZAIBBKOXfJ9Td3a0vvvhC4XA41S8FAEgzSY/Qa6+9poaGBrW0tOjTTz/VD3/4Q8ViMVVUVCT7pQAAaS7p/xz373//Wy+88IIuX76s8ePHa9asWTp+/Ljy8/OT/VIAgDSX9Ah98MEHyf4lgQGzYMECzzO/+93vPM9kZWV5nhkxwvs/XPzzn//0PCNxA1MMHO4dBwAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYSfkPtQMsfPvb3+7X3J/+9CfPM9euXfM8c/36dc8zY8aM8Tzz6KOPep6RpIyMDM8z/fk9AVwJAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAx30cagN27cOM8zn3zySb9e69NPP/U88/TTT3uemTx5sueZqqoqzzPLly/3PCNJa9as8Tzzxhtv9Ou1MLxxJQQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOEGphj0Dhw44HkmGAz267WWLVvWrzmv/vGPf3ieOXfunOcZn8/neUaSiouL+zUHeMWVEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghhuYYkAVFRV5npk6darnmc2bN3uekaS2trZ+zQ1WzrkBnQO84koIAGCGCAEAzHiO0NGjR7Vo0SLl5ubK5/Np3759Cc8751RdXa3c3FxlZGSopKREZ86cSdZ6AQBDiOcIdXV1adq0aaqtre3z+U2bNmnLli2qra3ViRMnFAqF9NRTT6mzs/OBFwsAGFo8fzChrKxMZWVlfT7nnNObb76pdevWqby8XJK0Y8cO5eTkaNeuXXrppZcebLUAgCElqe8JtbS0KBKJqLS0NP6Y3+/X3Llz1djY2OdMd3e3YrFYwgYAGB6SGqFIJCJJysnJSXg8Jycn/tyX1dTUKBgMxre8vLxkLgkAMIil5NNxPp8v4WvnXK/H7lq7dq2i0Wh8a21tTcWSAACDUFK/WTUUCkm6c0UUDofjj7e3t/e6OrrL7/fL7/cncxkAgDSR1CuhgoIChUIh1dXVxR/r6elRQ0ODiouLk/lSAIAhwPOV0NWrV3Xu3Ln41y0tLTp16pQyMzM1ceJErV69Whs2bNCkSZM0adIkbdiwQY888ohefPHFpC4cAJD+PEfos88+07x58+JfV1VVSZIqKir029/+VmvWrNH169e1YsUKXblyRUVFRfr4448VCASSt2oAwJDgOUIlJSX3vLmhz+dTdXW1qqurH2RdGKIOHjzoeeby5cueZ9555x3PMwAGHveOAwCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgJmk/mRVDC8LFizwPDNu3DjPMz/5yU88z7S1tXmeATDwuBICAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMxwA1P025IlSwbkdRobGwfkdQZSIBDwPPP00097nvH5fJ5nHmQO8IorIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADDcwRb8VFBRYL2FQ6M/NSDdt2uR5Zv78+Z5nnHOeZx5kDvCKKyEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAw3MEW/3bhxw3oJSVdYWOh5ZuPGjZ5n+nMz0itXrnieGTdunOcZYCBxJQQAMEOEAABmPEfo6NGjWrRokXJzc+Xz+bRv376E55ctWyafz5ewzZo1K1nrBQAMIZ4j1NXVpWnTpqm2tvYr91m4cKHa2tri28GDBx9okQCAocnzBxPKyspUVlZ2z338fr9CoVC/FwUAGB5S8p5QfX29srOzNXnyZC1fvlzt7e1fuW93d7disVjCBgAYHpIeobKyMr3//vs6fPiwNm/erBMnTmj+/Pnq7u7uc/+amhoFg8H4lpeXl+wlAQAGqaR/n9DSpUvj/z1lyhTNmDFD+fn5OnDggMrLy3vtv3btWlVVVcW/jsVihAgAhomUf7NqOBxWfn6+mpub+3ze7/fL7/enehkAgEEo5d8n1NHRodbWVoXD4VS/FAAgzXi+Erp69arOnTsX/7qlpUWnTp1SZmamMjMzVV1drSVLligcDuvChQt6/fXXlZWVpeeeey6pCwcApD/PEfrss880b968+Nd338+pqKjQ1q1bdfr0ae3cuVP//e9/FQ6HNW/ePO3evVuBQCB5qwYADAmeI1RSUiLn3Fc+f+jQoQdaENLHnj17PM8888wznmd+9rOfeZ45e/as5xlJ+tWvfuV5Jisry/NMXV2d55nKykrPM/09Drm5uZ5nMjIyPM9cv37d8wyGFu4dBwAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADM+d69bYhuIxWIKBoPWy0CK/Oc///E8M5A/ELGpqcnzzJkzZzzPvPLKK55n+vP/i0uXLnme6a/p06d7njl16lTyF4JBIxqNauzYsffchyshAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMDMQ9YLwPDy6KOPep750Y9+lIKV9G3btm2eZ3p6elKwkuS8Tn19fb9eq6SkxPPM448/7nmGG5iCKyEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAw3MMWAikajnmfeeuutFKwk/dy6dcvzTCwWS8FK+jZiBH+nhXecNQAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGW5gCgxhe/bs6dfcM88843lmyZIlnmfeffddzzMYWrgSAgCYIUIAADOeIlRTU6OZM2cqEAgoOztbixcv1tmzZxP2cc6purpaubm5ysjIUElJic6cOZPURQMAhgZPEWpoaFBlZaWOHz+uuro63bx5U6Wlperq6orvs2nTJm3ZskW1tbU6ceKEQqGQnnrqKXV2diZ98QCA9ObpgwkfffRRwtfbt29Xdna2mpqaNGfOHDnn9Oabb2rdunUqLy+XJO3YsUM5OTnatWuXXnrppeStHACQ9h7oPaG7P6o5MzNTktTS0qJIJKLS0tL4Pn6/X3PnzlVjY2Ofv0Z3d7disVjCBgAYHvodIeecqqqq9MQTT2jKlCmSpEgkIknKyclJ2DcnJyf+3JfV1NQoGAzGt7y8vP4uCQCQZvodoZUrV+rzzz/X73//+17P+Xy+hK+dc70eu2vt2rWKRqPxrbW1tb9LAgCkmX59s+qqVau0f/9+HT16VBMmTIg/HgqFJN25IgqHw/HH29vbe10d3eX3++X3+/uzDABAmvN0JeSc08qVK7V3714dPnxYBQUFCc8XFBQoFAqprq4u/lhPT48aGhpUXFycnBUDAIYMT1dClZWV2rVrl/785z8rEAjE3+cJBoPKyMiQz+fT6tWrtWHDBk2aNEmTJk3Shg0b9Mgjj+jFF19MyW8AAJC+PEVo69atkqSSkpKEx7dv365ly5ZJktasWaPr169rxYoVunLlioqKivTxxx8rEAgkZcEAgKHD55xz1ov4f7FYTMFg0HoZwLDWnz8WTp065Xnm8ccf9zyD9BGNRjV27Nh77sO94wAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCmXz9ZFcDQ9oc//MHzzOLFiz3PfP/73/c889e//tXzDAYvroQAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADM+55yzXsT/i8ViCgaD1ssAhrX+3Iz0j3/8o+eZc+fOeZ6ZN2+e55lIJOJ5Bg8uGo1q7Nix99yHKyEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAw3MAWQFP256enrr7/ueaawsNDzzKRJkzzPSNL58+f7NYc7uIEpAGBQI0IAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMcANTAEBKcANTAMCgRoQAAGY8RaimpkYzZ85UIBBQdna2Fi9erLNnzybss2zZMvl8voRt1qxZSV00AGBo8BShhoYGVVZW6vjx46qrq9PNmzdVWlqqrq6uhP0WLlyotra2+Hbw4MGkLhoAMDQ85GXnjz76KOHr7du3Kzs7W01NTZozZ078cb/fr1AolJwVAgCGrAd6TygajUqSMjMzEx6vr69Xdna2Jk+erOXLl6u9vf0rf43u7m7FYrGEDQAwPPT7I9rOOT377LO6cuWKjh07Fn989+7d+sY3vqH8/Hy1tLToF7/4hW7evKmmpib5/f5ev051dbXeeOON/v8OAACD0v18RFuun1asWOHy8/Nda2vrPfe7dOmSGzVqlNuzZ0+fz9+4ccNFo9H41tra6iSxsbGxsaX5Fo1Gv7Ylnt4TumvVqlXav3+/jh49qgkTJtxz33A4rPz8fDU3N/f5vN/v7/MKCQAw9HmKkHNOq1at0ocffqj6+noVFBR87UxHR4daW1sVDof7vUgAwNDk6YMJlZWVeu+997Rr1y4FAgFFIhFFIhFdv35dknT16lW99tpr+tvf/qYLFy6ovr5eixYtUlZWlp577rmU/AYAAGnMy/tA+op/99u+fbtzzrlr16650tJSN378eDdq1Cg3ceJEV1FR4S5evHjfrxGNRs3/HZONjY2N7cG3+3lPiBuYAgBSghuYAgAGNSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAmUEXIeec9RIAAElwP3+eD7oIdXZ2Wi8BAJAE9/Pnuc8NskuP27dv69KlSwoEAvL5fAnPxWIx5eXlqbW1VWPHjjVaoT2Owx0chzs4DndwHO4YDMfBOafOzk7l5uZqxIh7X+s8NEBrum8jRozQhAkT7rnP2LFjh/VJdhfH4Q6Owx0chzs4DndYH4dgMHhf+w26f44DAAwfRAgAYCatIuT3+7V+/Xr5/X7rpZjiONzBcbiD43AHx+GOdDsOg+6DCQCA4SOtroQAAEMLEQIAmCFCAAAzRAgAYCatIvT222+roKBADz/8sAoLC3Xs2DHrJQ2o6upq+Xy+hC0UClkvK+WOHj2qRYsWKTc3Vz6fT/v27Ut43jmn6upq5ebmKiMjQyUlJTpz5ozNYlPo647DsmXLep0fs2bNsllsitTU1GjmzJkKBALKzs7W4sWLdfbs2YR9hsP5cD/HIV3Oh7SJ0O7du7V69WqtW7dOJ0+e1JNPPqmysjJdvHjRemkD6rHHHlNbW1t8O336tPWSUq6rq0vTpk1TbW1tn89v2rRJW7ZsUW1trU6cOKFQKKSnnnpqyN2H8OuOgyQtXLgw4fw4ePDgAK4w9RoaGlRZWanjx4+rrq5ON2/eVGlpqbq6uuL7DIfz4X6Og5Qm54NLE9/73vfcyy+/nPDYd77zHffzn//caEUDb/369W7atGnWyzAlyX344Yfxr2/fvu1CoZDbuHFj/LEbN264YDDofv3rXxuscGB8+Tg451xFRYV79tlnTdZjpb293UlyDQ0Nzrnhez58+Tg4lz7nQ1pcCfX09KipqUmlpaUJj5eWlqqxsdFoVTaam5uVm5urgoICPf/88zp//rz1kky1tLQoEokknBt+v19z584ddueGJNXX1ys7O1uTJ0/W8uXL1d7ebr2klIpGo5KkzMxMScP3fPjycbgrHc6HtIjQ5cuXdevWLeXk5CQ8npOTo0gkYrSqgVdUVKSdO3fq0KFD2rZtmyKRiIqLi9XR0WG9NDN3//cf7ueGJJWVlen999/X4cOHtXnzZp04cULz589Xd3e39dJSwjmnqqoqPfHEE5oyZYqk4Xk+9HUcpPQ5HwbdXbTv5cs/2sE51+uxoaysrCz+31OnTtXs2bP1rW99Szt27FBVVZXhyuwN93NDkpYuXRr/7ylTpmjGjBnKz8/XgQMHVF5ebriy1Fi5cqU+//xz/eUvf+n13HA6H77qOKTL+ZAWV0JZWVkaOXJkr7/JtLe39/obz3AyZswYTZ06Vc3NzdZLMXP304GcG72Fw2Hl5+cPyfNj1apV2r9/v44cOZLwo1+G2/nwVcehL4P1fEiLCI0ePVqFhYWqq6tLeLyurk7FxcVGq7LX3d2tL774QuFw2HopZgoKChQKhRLOjZ6eHjU0NAzrc0OSOjo61NraOqTOD+ecVq5cqb179+rw4cMqKChIeH64nA9fdxz6MmjPB8MPRXjywQcfuFGjRrl3333X/f3vf3erV692Y8aMcRcuXLBe2oB59dVXXX19vTt//rw7fvy4+8EPfuACgcCQPwadnZ3u5MmT7uTJk06S27Jlizt58qT717/+5ZxzbuPGjS4YDLq9e/e606dPuxdeeMGFw2EXi8WMV55c9zoOnZ2d7tVXX3WNjY2upaXFHTlyxM2ePdt985vfHFLH4ZVXXnHBYNDV19e7tra2+Hbt2rX4PsPhfPi645BO50PaRMg559566y2Xn5/vRo8e7aZPn57wccThYOnSpS4cDrtRo0a53NxcV15e7s6cOWO9rJQ7cuSIk9Rrq6iocM7d+Vju+vXrXSgUcn6/382ZM8edPn3adtEpcK/jcO3aNVdaWurGjx/vRo0a5SZOnOgqKircxYsXrZedVH39/iW57du3x/cZDufD1x2HdDof+FEOAAAzafGeEABgaCJCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzPwPpqLKhNYfDbIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(data,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqF_zKNkQD0F"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO4CO/iFklpLRJjowQ5Vuac",
   "collapsed_sections": [],
   "name": "convolutional_network_raw.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
