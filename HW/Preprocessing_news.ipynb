{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Hfbb2nzl9DZ"
   },
   "source": [
    "# Pre-processing News Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1elcGz7huoP"
   },
   "source": [
    "## Bài toán\n",
    "Dữ liệu gồm n văn bản phân vào 10 chủ đề khác nhau. Cần biễu diễn mỗi văn bản dưới dạng một vector số thể hiện cho nội dụng của văn bản đó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyy4DDvuhuoU"
   },
   "source": [
    "## Mục lục\n",
    "- Load dữ liệu từ thư mục\n",
    "- Loại bỏ các stop words\n",
    "- Sử dụng thư viện để mã hóa TF-IDF cho mỗi văn bản"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_akck0KhuoW"
   },
   "source": [
    "## Phương pháp mã hóa: TF-IDF\n",
    "Cho tập gồm $n$ văn bản: $D = \\{d_1, d_2, ... d_n\\}$. Tập từ điển tương ứng được xây dựng từ $n$ văn bản này có độ dài là $m$\n",
    "- Xét văn bản $d$ có $|d|$ từ và $t$ là một từ trong $d$. Mã hóa tf-idf của $t$ trong văn bản $d$ được biểu diễn:\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\text{tf}_{t, d} &= \\frac{f_t}{|d|} \\\\\n",
    "        \\text{idf}_{t, d} &= \\log\\frac{n}{n_t}, \\ \\ \\ \\ n_t = |\\{d\\in D: t\\in d\\}| \\\\\n",
    "        \\text{tf-idf}_{t d} &= \\text{tf}_{t, d} \\times \\text{idf}_{t, d}\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "- Khi đó văn bản $d$ được mã hóa là một vector $m$ chiều. Các từ xuất hiện trong d sẽ được thay bằng giá trị tf-idf tương ứng. Các từ không xuất hiện trong $d$ thì thay là 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from pyvi import ViTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqNL4mwDhuoa"
   },
   "source": [
    "## Load dữ liệu từ thư mục\n",
    "\n",
    "Cấu trúc thư mục như sau \n",
    "\n",
    "- data/news_vnexpress/\n",
    "\n",
    "    - Kinh tế: \n",
    "        - bài báo 1.txt \n",
    "        - bài báo 2.txt \n",
    "    - Pháp luật\n",
    "        - bài báo 3.txt \n",
    "        - bài báo 4.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tty49E_ohuoa"
   },
   "outputs": [],
   "source": [
    "INPUT = 'data/news_vnexpress'\n",
    "os.makedirs(\"images\",exist_ok=True)  # thư mục lưu các các hình ảnh trong quá trình huấn luyện và đánh gía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ru3Ct7Zphuob",
    "outputId": "89c2f590-efaa-4a4e-c0c5-9b676fa63b7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các nhãn và số văn bản tương ứng trong dữ liệu\n",
      "----------------------------------------------\n",
      "doi-song: 120\n",
      "du-lich: 54\n",
      "giai-tri: 201\n",
      "giao-duc: 105\n",
      "khoa-hoc: 144\n",
      "kinh-doanh: 262\n",
      "phap-luat: 59\n",
      "suc-khoe: 162\n",
      "the-thao: 173\n",
      "thoi-su: 59\n",
      "-------------------------\n",
      "Tổng số văn bản: 1339\n"
     ]
    }
   ],
   "source": [
    "# statistics\n",
    "print('Các nhãn và số văn bản tương ứng trong dữ liệu')\n",
    "print('----------------------------------------------')\n",
    "n = 0\n",
    "for label in os.listdir(INPUT):\n",
    "    print(f'{label}: {len(os.listdir(os.path.join(INPUT, label)))}')\n",
    "    n += len(os.listdir(os.path.join(INPUT, label)))\n",
    "\n",
    "print('-------------------------')\n",
    "print(f\"Tổng số văn bản: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "j3tycWTfhuoc",
    "outputId": "bae88ffb-a53a-4a1e-a9a5-2955b60ba8c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping:\n",
      "doi-song - 0\n",
      "du-lich - 1\n",
      "giai-tri - 2\n",
      "giao-duc - 3\n",
      "khoa-hoc - 4\n",
      "kinh-doanh - 5\n",
      "phap-luat - 6\n",
      "suc-khoe - 7\n",
      "the-thao - 8\n",
      "thoi-su - 9\n",
      "--------------------------\n",
      "['data/news_vnexpress\\\\khoa-hoc\\\\00133.txt']\n",
      "[4]\n",
      "['Mời độc giả đặt câu hỏi tại đây\\n']\n",
      "\n",
      "Tổng số  văn bản: 1339\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_train = load_files(container_path=INPUT, encoding=\"utf-8\")\n",
    "print('mapping:')\n",
    "for i in range(len(data_train.target_names)):\n",
    "    print(f'{data_train.target_names[i]} - {i}')\n",
    "\n",
    "print('--------------------------')\n",
    "print(data_train.filenames[0:1])\n",
    "# print(data_train.data[0:1])\n",
    "print(data_train.target[0:1])\n",
    "print(data_train.data[0:1])\n",
    "\n",
    "print(\"\\nTổng số  văn bản: {}\" .format( len(data_train.filenames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HU06Y_BKhuoe"
   },
   "source": [
    "## Chuyển dữ liệu dạng text về ma trận (n x m) bằng TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6vG0C2ima31"
   },
   "source": [
    "* Bạn cần viết đoạn mã tương ứng trong cell bên dưới. Theo các bước được gợi ý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ns9j8Hgrhuof",
    "outputId": "11600006-3227-4e0e-91af-e4afd76d7fef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng stopwords: 1942\n",
      "['a lô', 'a ha', 'ai', 'ai ai', 'ai nấy', 'ai đó', 'alô', 'amen', 'anh', 'anh ấy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['bao', 'bay', 'biến', 'biệt', 'bây', 'bõm', 'bảo', 'bất', 'bẩy', 'bập', 'bắt', 'bội', 'chao', 'chi', 'chia', 'chu', 'chui', 'chuẩn', 'chà', 'chành', 'chí', 'chót', 'chùn', 'chăn', 'chũn', 'chưng', 'chạnh', 'chả', 'chầm', 'chầy', 'chập', 'chắn', 'chẳng', 'chết', 'chốc', 'chừ', 'chừng', 'coi', 'cu', 'cá', 'câu', 'cóc', 'công', 'cạnh', 'cảm', 'cầu', 'cật', 'cắt', 'cổ', 'cụ', 'cục', 'cực', 'da', 'dà', 'dĩ', 'dưng', 'dần', 'dầu', 'dịp', 'dở', 'dụng', 'gian', 'giá', 'giác', 'giời', 'ha', 'hiện', 'hoàn', 'hèn', 'hình', 'hô', 'hầu', 'hậu', 'hẳn', 'hồ', 'hỗ', 'hội', 'hợp', 'hự', 'khói', 'khô', 'khăn', 'khắc', 'khẳng', 'kia', 'kiện', 'kê', 'kì', 'kìa', 'kỳ', 'lai', 'le', 'liên', 'liệt', 'loạt', 'luận', 'luật', 'luốt', 'lình', 'lí', 'lô', 'lý', 'lập', 'lẽ', 'lị', 'lự', 'lực', 'mày', 'mòi', 'mù', 'mạng', 'mấy', 'mẹ', 'mực', 'nghiễm', 'ngõ', 'ngăn', 'ngắt', 'ngộ', 'ngờ', 'nhiên', 'nhiêu', 'nhiệt', 'nhung', 'nhân', 'nhén', 'nhón', 'nhăng', 'nhược', 'nhỡ', 'nả', 'nỗi', 'nở', 'nức', 'oai', 'phi', 'phui', 'phàm', 'phù', 'phăn', 'phương', 'phỉ', 'quan', 'qui', 'quy', 'quyết', 'ren', 'riu', 'ríu', 'rón', 'rút', 'rốt', 'sa', 'sinh', 'song', 'sả', 'sẻ', 'sốt', 'sột', 'sở', 'sợ', 'sức', 'sử', 'ta', 'te', 'tha', 'than', 'thay', 'thi', 'thiên', 'thiết', 'thoảng', 'thành', 'thái', 'tháo', 'thân', 'thình', 'thúng', 'thương', 'thảo', 'thảy', 'thắng', 'thể', 'thỉnh', 'thị', 'thời', 'thục', 'thử', 'thực', 'tiên', 'tiếp', 'tiện', 'tiệt', 'toàn', 'toé', 'trung', 'tráo', 'trình', 'trí', 'trạng', 'trạo', 'trếu', 'trệu', 'trị', 'trọi', 'trọng', 'trời', 'trở', 'trợ', 'trừ', 'trực', 'tuyệt', 'tuần', 'tuốt', 'tuồn', 'tuồng', 'tuột', 'tà', 'tàn', 'tán', 'tâm', 'tê', 'tì', 'tình', 'tít', 'tò', 'tông', 'tù', 'tăm', 'tả', 'tất', 'tần', 'tập', 'tật', 'tế', 'tề', 'tỏ', 'tốc', 'tối', 'tục', 'tức', 'tử', 'tựu', 'vung', 'vàn', 'ví', 'vô', 'văng', 'vạn', 'vả', 'vấn', 'vẻ', 'vị', 'vốn', 'xiết', 'xon', 'xoành', 'xoạch', 'xuất', 'xón', 'xúi', 'xăm', 'xưa', 'xả', 'xảy', 'xắm', 'xềnh', 'xệch', 'xử', 'xửa', 'yêu', 'âu', 'ôi', 'đi', 'đành', 'đán', 'đánh', 'đáo', 'đùng', 'đơn', 'đạch', 'đại', 'đảm', 'đất', 'đấy', 'đầu', 'đặc', 'đề', 'địa', 'định', 'đối', 'đồ', 'đồng', 'đổi', 'ơn', 'ầu', 'ối'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Số lượng từ trong từ điển: 12797\n",
      "Kích thước dữ liệu sau khi xử lý: (1339, 12797)\n",
      "Kích thước nhãn tương ứng: (1339,)\n"
     ]
    }
   ],
   "source": [
    "# load dữ liệu các stopwords \n",
    "\n",
    "#---> Code ở đây\n",
    "with open('data/vietnamese-stopwords.txt', 'r', encoding = 'utf-8') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [word.strip() for word in stopwords]\n",
    "print(f\"Số lượng stopwords: {len(stopwords)}\")\n",
    "print(stopwords[:10])\n",
    "# Chuyển hoá dữ liệu text về dạng vector TF \n",
    "#     - loại bỏ từ dừng\n",
    "#     - sinh từ điển\n",
    "module_count_vector = CountVectorizer(stop_words=stopwords) \n",
    "#Chuyển đổi dữ liệu thủ công\n",
    "X_counts = module_count_vector.fit_transform(data_train.data) #chuyển văn bản về dạng ma trận đếm tần số xuất hiện của từ\n",
    "tfidf_transformer = TfidfTransformer() \n",
    "\n",
    "# Chuyển đổi dữ liệu tự động với Pipeline\n",
    "# tfidf_transformer = Pipeline([('vect', module_count_vector),\n",
    "#                     ('tfidf', TfidfTransformer()),\n",
    "#                     ])\n",
    "\n",
    "\n",
    "# Hàm thực hiện chuyển đổi dữ liệu text thành dữ liệu số dạng ma trận \n",
    "# Input: Dữ liệu 2 chiều dạng numpy.array, mảng nhãn id dạng numpy.array \n",
    "\n",
    "data_preprocessed = tfidf_transformer.fit_transform(X_counts) #chuyển ma trận đếm tần số về dạng tf-idf\n",
    "\n",
    "X = data_preprocessed # thuoc tinh\n",
    "Y = data_train.target #nhan\n",
    "\n",
    "print(f\"\\nSố lượng từ trong từ điển: {len(module_count_vector.vocabulary_)}\")\n",
    "print(f\"Kích thước dữ liệu sau khi xử lý: {X.shape}\")\n",
    "print(f\"Kích thước nhãn tương ứng: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CzIuAyLphuoi",
    "outputId": "7badd4f6-b1b2-4c6f-fd13-f43ec0f5476c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.14048828 0.        ]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(X[100].toarray())\n",
    "print(Y[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "apf3ulZhhuoi",
    "outputId": "d1d244bd-e0a9-445d-ecfd-530abff20bc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(289)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(X[100].toarray() != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5FjwPJlfhuoj",
    "outputId": "6481ea2f-dcaf-45eb-e5dc-d7b157f7a896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 289 stored elements and shape (1, 12797)>\n",
      "  Coords\tValues\n",
      "  (0, 81)\t0.015211595534715633\n",
      "  (0, 100)\t0.020769547555053954\n",
      "  (0, 156)\t0.023262873797037953\n",
      "  (0, 188)\t0.04722498744523733\n",
      "  (0, 269)\t0.03324036700472501\n",
      "  (0, 392)\t0.024783841259467605\n",
      "  (0, 397)\t0.034232954192352914\n",
      "  (0, 418)\t0.048918066523847725\n",
      "  (0, 662)\t0.022769929356223215\n",
      "  (0, 909)\t0.033182248640039956\n",
      "  (0, 1194)\t0.05117031195708949\n",
      "  (0, 1209)\t0.10234062391417897\n",
      "  (0, 1219)\t0.05117031195708949\n",
      "  (0, 1271)\t0.016005705134410072\n",
      "  (0, 1590)\t0.034926623903062066\n",
      "  (0, 1631)\t0.023493949966261335\n",
      "  (0, 1783)\t0.04734509560871461\n",
      "  (0, 1866)\t0.05117031195708949\n",
      "  (0, 2076)\t0.014547704347804936\n",
      "  (0, 2101)\t0.02693672471116765\n",
      "  (0, 2111)\t0.02577563465433512\n",
      "  (0, 2135)\t0.04322051581452055\n",
      "  (0, 2140)\t0.01566196368628259\n",
      "  (0, 2159)\t0.01608450478874651\n",
      "  (0, 2170)\t0.02950839772591026\n",
      "  :\t:\n",
      "  (0, 12272)\t0.021259537682082122\n",
      "  (0, 12454)\t0.0758997005019029\n",
      "  (0, 12510)\t0.01778617457985167\n",
      "  (0, 12518)\t0.038832198646960935\n",
      "  (0, 12522)\t0.09355442947181114\n",
      "  (0, 12536)\t0.05488370325838489\n",
      "  (0, 12548)\t0.045752865989427884\n",
      "  (0, 12559)\t0.03206234356763186\n",
      "  (0, 12567)\t0.03324036700472501\n",
      "  (0, 12585)\t0.038767743735542225\n",
      "  (0, 12592)\t0.07519534686809995\n",
      "  (0, 12618)\t0.08000423234784887\n",
      "  (0, 12625)\t0.3318224864003996\n",
      "  (0, 12627)\t0.019288093792759513\n",
      "  (0, 12630)\t0.02417303634575905\n",
      "  (0, 12644)\t0.030193779677554423\n",
      "  (0, 12647)\t0.042689479937610325\n",
      "  (0, 12673)\t0.03173992101554847\n",
      "  (0, 12692)\t0.020769547555053954\n",
      "  (0, 12693)\t0.013885134230282651\n",
      "  (0, 12698)\t0.03935911209707955\n",
      "  (0, 12706)\t0.024927343279465622\n",
      "  (0, 12715)\t0.03437923951819016\n",
      "  (0, 12725)\t0.05122667806048764\n",
      "  (0, 12795)\t0.14048828324700807\n"
     ]
    }
   ],
   "source": [
    "print(X[100])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Preprocessing_news.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
